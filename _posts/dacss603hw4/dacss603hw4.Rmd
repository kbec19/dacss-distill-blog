---
title: "DACSS 603 Homework 4"
description: |
  Transformations & Logistic Regression and Final Project Status
categories:
  - statistics
  - homework
author:
  - name: Kristina Becvar
    url: https://www.kristinabecvar.com
slug: dacss603hw4
date: 2022-04-13
output:
  distill::distill_article:
    toc: true
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(smss)
library(alr4)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(broom)
```

# Part 1

## Question 1

*(SMSS 14.3, 14.4, merged & modified, using data file "house.selling.price.2" from smss R package)*

*For the house.selling.price.2 data the tables show a correlation matrix and a model fit using four predictors of selling price. With these four predictors,*

## Answer

First, I will re-create the correlation matrix and the model fit table from the question.

```{r code_folding = TRUE}
#load the data and create a data frame
data("house.selling.price.2")
df1 <- as_tibble(house.selling.price.2)
#assign column names to represent variables accurately
colnames(df1) <- c("Price", "Size", "Beds", "Baths", "New")
#create a correlation matrix and round to 3 decimals
df1corr <- cor(df1)
round(df1corr, 3)

#run the linear model
lm1a <- lm(Price ~ ., data = df1)
#create a data frame from the model results
tidylm1a <- tidy(lm1a, conf.int = FALSE) 
#round the results to 3 decimal points
tidylm1a %>%
  mutate_if(is.numeric, round, 3)
```

### A

*For backward elimination, which variable would be deleted first? Why?*

For backward elimination, the first variable to be deleted would be the "Beds" variable. The p-value of 0.467 is the largest value of the options, meaning it is the least signficant variable.  

### B

*For forward selection, which variable would be added first? Why?*

For forward selection, the first variable to be added would be "Size". Both "Size" and "New" have p-values < 0.001. However, when looking at the correlation matrix, the "Size" variable is more positively correlated with the "Price" variable by a significant difference.

### C
 
*Why do you think that BEDS has such a large P-value in the multiple regression model, even though it has a substantial correlation with PRICE?*

The "Beds" variable has a large p-value despite a substantial correlation with "Price" (0.590) most likely because there is nothing about the correlation that adds something to the model that is not already represented by another variable. Since the "Beds" variable is even more correlated (0.669) with the "Size" variable than "Price", the number of bedrooms and size of the home may be redundant.

### D

*Using software with these four predictors, find the model that would be selected using each criterion:*

* *R2*
* *Adjusted R2*
* *AIC*
* *BIC*

For "R2" and "Adjusted R2", I could use the "summary" function on my "lm()" call.

However, I can use the "broom" package "glance()" function to view the AIC and BIC scores, among other relevant information:

```{r code_folding=TRUE}
#using the "glance" function in the "broom" package
tidylm1a <- broom::glance(lm1a) %>%
  mutate_if(is.numeric, round, 4)

knitr::kable(tidylm1a)
```
* *PRESS*

For "PRESS", I will create the "PRESS" function and save the result to my data frame

```{r code_folding = TRUE}
#create the "PRESS" function
PRESS <- function(linear.model) {
    pr <- residuals(linear.model)/(1 - lm.influence(linear.model)$hat)
    sum(pr^2)
}
#use the "PRESS()" function
PRESS(lm1a)
#save to data frame
press1a <- PRESS(lm1a)
tidylm1a$press <- press1a
```

I want to now follow that same process with the model excluding the "Beds" variable: 

```{r code_folding = TRUE}
#run the new linear model
lm1b <- lm(Price ~ . -Beds, data = df1)
#using the "glance" function in the "broom" package
tidylm1b <- broom::glance(lm1b) %>%
  mutate_if(is.numeric, round, 4)
#save PRESS evaluation to data frame
press1b <- PRESS(lm1b)
tidylm1b$press <- press1b


knitr::kable(tidylm1b)
```

Now I can combine the data into one data frame and choose the relevant columns to examine them more easily:

```{r code_folding = TRUE}
#join the data frames
compare_df <- full_join(tidylm1a, tidylm1b)
tidylm1c <- compare_df %>%
  mutate_if(is.numeric, round, 4) %>%
  select("r.squared", "adj.r.squared", "AIC", "BIC", "press")
knitr::kable(tidylm1c)
```

### E

*Explain which model you prefer and why.*

Comparing all 5 of the criterion, all of them are lower in the second model except the adjusted r squared. Although adjusted r squared is an important criterion, the difference (+0.0008) is negligible. Given the strong message from the other 4 criteria and the fact that the second model removed a predictor variable that was not statistically significant by any reasonable degree, I feel confident in saying the second model is the best.


## Question 2

*From the documentation:*

*"This data set provides measurements of the diameter, height and volume of timber in 31 felled black cherry trees. Note that the diameter (in inches) is erroneously labelled Girth in the data. It is measured at 4 ft 6 in above the ground.”*

*Tree volume estimation is a big deal, especially in the lumber industry. Use the trees data to build a basic model of tree volume prediction.*

## Answer

First, I will import the data from base R and take a look at it. While doing so, I will correct the variable "Girth" to read "Diameter":

```{r code_folding = TRUE}
#load the data and create a data frame
data("trees")
df2 <- trees %>%
  rename(Diameter = Girth)
head(df2)
```

### A

*Fit a multiple regression model with the "Volume" as the outcome and "Diameter" and "Height" as the explanatory variables*

```{r code_folding = TRUE}
#run the linear model
lm2 <- lm(Volume ~ ., data = df2)
summary(lm2)
```

### B

*Run regression diagnostic plots on the model.* 

```{r code_folding = TRUE}
par(mfrow = c(1,1))
plot(lm2, 1:6)
```

### C

*Based on the plots, do you think any of the regression assumptions is violated?*

For **Residuals vs Fitted**, I can see that the assumption of **_linearity_** has been violated since we do not have residuals bouncing randomly around a horizontal line. Additionally, the assumption of  **_constant variance_** is violated due to the funnel shape of the regression line rather than appearing as a horizontal band.

For **Normal Q-Q**, I can see that the assumption of **_normality_** is seemingly upheld by the observations generally falling along the line. However, to check more formally for normality in the Normal Q-Q plot, I will use the Shapiro-Wilk Test:

```{r code_folding=TRUE}
shapiro.test(df2$Diameter)
shapiro.test(df2$Height)
```

Both the p-values given for Diameter and Height in the Shapiro-Wilk normality test are <0.5, so it seems reasonable that we should not reject the null hypothesis that the distribution is normal for each set of observations. \

Both visual inspection of the Normal Q-Q test and the calculations of the Shapiro-Wilk tests help me to observe that the normality assumption is not being violated. However, having n=31 for observations, I am also mindful that the low sample size should leave some room for uncertainty.

For **Scale-Location**, the assumption of **_constant variance_** seems to be violated, as the residuals do not follow an approximately horizontal line. However, to check more formally for heteroskedasticity in the Scale-Location plot, I will use the Breusch Pagan Test:

```{r code_folding=TRUE}
library(lmtest)
bptest(lm2)
```

The resulting p-value indicates that I cannot rule out the null hypothesis of homoskedasticity.

For **Cook's Distance**, I can see that there are clearly several observations that violate the assumption of **_influential observations_**. Using the guideline of looking at observations larger than 4/n (0.129), I can see that observation #13 is far beyond that threshold. This tells me that observation is highly influential and not representative of the dataset as a whole.

Looking at **Residuals vs Leverage** and **Cook's Distance vs Leverage**, at least one observation (31) in each model indicates a larger potential influence on the regression model than we want to see.


## Question 3

*In the 2000 election for U.S. president, the counting of votes in Florida was controversial. In Palm Beach County in south Florida, for example, voters used a so-called butterfly ballot. Some believe that the layout of the ballot caused some voters to cast votes for Buchanan when their intended choice was Gore.*

*The data has variables for the number of votes for each candidate—Gore, Bush, and Buchanan. Run a simple linear regression model where the Buchanan vote is the outcome and the Bush vote is the explanatory variable. Produce the regression diagnostic plots. Is Palm Beach County an outlier based on the diagnostic plots? Why or why not?*

## Answer

First, I will import the data from the "alr" package:

```{r code_folding = TRUE}
#load the data and create a data frame
data("florida")
df3 <- as.data.frame(florida)
head(df3)
```

Running a simple linear regression model where the Buchanan vote is the outcome and the Bush vote is the explanatory variable:

```{r code_folding = TRUE}
#run the linear model
lm3 <- lm(Buchanan ~ Bush, data = df3)
options(scipen = 999)
summary(lm3)
```

Produce the regression diagnostic plots. Is Palm Beach County an outlier based on the diagnostic plots? Why or why not?

```{r code_folding = TRUE}
#produce the regression diagnostic plots
par(mfrow = c(1,1))
plot(lm3, which = 1:6)
```

Reviewing the diagnostic plots, Palm Beach County is definitely an outlier in every one of the diagnostic plots. 

With the exception of the outliers Dade and Palm Beach counties, the Normal Q-Q plot seems to represent an otherwise normal distribution.

Using the "augment() function from the "broom" package, I can look at the Cook's values and separate out the 3 highest Cook's values to confirm the level to which both Dade and Palm Beach counties show significantly high leverage than the third highest value.

```{r code_folding=TRUE}
#calculate cook's distance and select top 3 values
aug_lm3 <- augment(lm3) %>%
  select(.rownames, .cooksd) %>%
  slice_max(.cooksd, n=3)
knitr::kable(aug_lm3)
```

# Part 2 (Course Final Project)

## Question 1

*What is your research question for the final project?*

My preliminary thought of an appropriate research question will be a question involving a combination of data sources.

The first is a data set of observations from the World Values Survey conducted from 2017-2021 as a joint project between the World Values Survey and the European Values Studies. This data was released in July 2021, and contains responses from ~135,000 respondents among 95 countries.

The second is a data set of observations from novice "hacking tool" users of a tool to engage in DDOS (denial of service) attacks against Russian targets in March 2022. The data contains a total of users cumulatively for each day of the series March 2 through March 11, and the users represent participants from 98 counties.

Finally, the third is a data set of media coverage (media articles and social media mentions) of the Ukrainian minister's call for volunteers for the "IT Army of Ukraine" to help fight the invasion of Russia on the digital front.

My working ideas are:

1. Was the increase in DDOS participants increase with coverage of the call for volunteers in the media?

2. What countries and regions were most represented in the DDOS participants?

3. How does the representation of DDOS users relate to the sentiment of survey members from their respective countries to the World Values Survey questions regarding activism and political engagement?

## Question 2

*What is your hypothesis (i.e. an answer to the research question) that you want to test?*

I need to develop the hypothesis more thoroughly, but I feel so far that they will point in this direction:

H(1): The increase in DDOS participants was independent of the coverage for calls for volunteers in the media.

H(2): Countries in Europe and Western Asia were most represented in the DDOS participants.

H(3): There is a positive correlation between the sentiment of survey respondents from the countries of DDOS participants.



## Question 3

*Present some exploratory analysis. In particular:*

* *Numerically summarize (e.g. with the summary() function) the variables of interest (the outcome, the explanatory variable, the control variables).*

The data I imported for this first exploration is a data frame consisting of 98 observations with the columns:

* Country Name
* Population (as indicated by the U.S. CIA World factbook website)
* Region (as indicated by the UN classifications)
* Columns representing the cumulative number of participants in the DDOS attack from each representative country as of a given day from March 2 to March 11, 2022.

```{r code_folding = TRUE}
#load the data
ddos <- read_csv("fckptn active observations.csv")
#assign column names to represent variables accurately
colnames(ddos) <- c("Country", "Population", "Region", "March2", "March3", "March4", "March5", "March6", "March7", "March8", "March9", "March10", "March11")
#summarize the data
summary(ddos)
```

The total DDOS users as of the first day of observations, March 2, 2022, and the last day available for observation, March 11, 2022 began at 7,850 and grew to a total of 48,879.

```{r code_folding = TRUE}
sum(ddos$March2)
sum(ddos$March11)
```

* Plot the relationships between key variables. You can do this any way you want, but one straightforward way of doing this would be with the pairs() function or other scatter plots / box plots. Interpret what you see.

```{r code_folding=TRUE}
#create plot
ggplot(ddos, aes(x = log(Population), y = log(March11), color = Region)) +
  geom_point () +
  facet_wrap("Region")
```

